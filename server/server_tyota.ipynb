{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_dummies(cat_features: list, df: pd.DataFrame): # -> pd.DataFrame:\n",
    "    \"\"\" Converts the catergorial features to a numeric features\n",
    "\n",
    "    Args:\n",
    "        cat_features (list): List of the catergorial features in the dataframe\n",
    "                             that yo want to turn into numeric features\n",
    "        df (pd.DataFrame): The DataFrame which u want to convert\n",
    "                            the catergorial features to numeric features\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dateframe with converted features\n",
    "    \"\"\"\n",
    "    for feature in cat_features:\n",
    "        temp_dummy = pd.get_dummies(df[feature])\n",
    "        df = pd.concat([temp_dummy, df], axis=1)\n",
    "    df = df.drop(cat_features, axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import file: ..\\clean database\\Clean_Data_1.csv\n",
      "import file: ..\\clean database\\Clean_Data_10.csv\n",
      "import file: ..\\clean database\\Clean_Data_11.csv\n",
      "import file: ..\\clean database\\Clean_Data_12.csv\n",
      "import file: ..\\clean database\\Clean_Data_2.csv\n",
      "import file: ..\\clean database\\Clean_Data_3.csv\n",
      "import file: ..\\clean database\\Clean_Data_4.csv\n",
      "import file: ..\\clean database\\Clean_Data_5.csv\n",
      "import file: ..\\clean database\\Clean_Data_6.csv\n",
      "import file: ..\\clean database\\Clean_Data_7.csv\n",
      "import file: ..\\clean database\\Clean_Data_8.csv\n",
      "import file: ..\\clean database\\Clean_Data_9.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#path\n",
    "path_clean_data='..\\clean database'\n",
    "\n",
    "#load  and merge csv files\n",
    "all_files = glob.glob(path_clean_data + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    print(\"import file: {}\".format(filename))\n",
    "    df = pd.read_csv(filename, index_col=0, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "main_df  = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "main_df = main_df.sort_values(by=['zone','pickup_date','time_binned'])\n",
    "\n",
    "\n",
    "main_df.dropna(inplace=True)\n",
    "main_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "##convert zone feature to string\n",
    "main_df['zone'] = main_df['zone'].astype(str)\n",
    "\n",
    "main_df.head()\n",
    "\n",
    "\n",
    "main_df.dropna(inplace=True)\n",
    "main_df.drop_duplicates(inplace=True)\n",
    "main_df.drop(['pickup_date', 'trip_distance', 'speed'], axis=1, inplace=True) #drop unneeded features\n",
    "\n",
    "main_df = main_df.drop(['Tmax','Tmin','HDD'], axis=1) #remove features with high correlation\n",
    "\n",
    "main_df['trip_time'] = main_df.trip_time.apply(np.ceil) #round up trip time to nearest integer\n",
    "\n",
    "\n",
    "main_df = get_dummies(['weekday','time_binned','zone'],main_df) #dummy variables before we split to 3 sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import file: ..\\clean database\\Clean_Data_1.csv\n",
      "import file: ..\\clean database\\Clean_Data_10.csv\n",
      "import file: ..\\clean database\\Clean_Data_11.csv\n",
      "import file: ..\\clean database\\Clean_Data_12.csv\n",
      "import file: ..\\clean database\\Clean_Data_2.csv\n",
      "import file: ..\\clean database\\Clean_Data_3.csv\n",
      "import file: ..\\clean database\\Clean_Data_4.csv\n",
      "import file: ..\\clean database\\Clean_Data_5.csv\n",
      "import file: ..\\clean database\\Clean_Data_6.csv\n",
      "import file: ..\\clean database\\Clean_Data_7.csv\n",
      "import file: ..\\clean database\\Clean_Data_8.csv\n",
      "import file: ..\\clean database\\Clean_Data_9.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time_binned</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>Tdep</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>new_snow</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>num_of_taxis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>00:00 - 00:59</td>\n",
       "      <td>48.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>01:00 - 01:59</td>\n",
       "      <td>48.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>02:00 - 02:59</td>\n",
       "      <td>48.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>03:00 - 03:59</td>\n",
       "      <td>48.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>04:00 - 04:59</td>\n",
       "      <td>48.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529357</th>\n",
       "      <td>263</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>19:00 - 19:59</td>\n",
       "      <td>40.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529358</th>\n",
       "      <td>263</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>20:00 - 20:59</td>\n",
       "      <td>40.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529359</th>\n",
       "      <td>263</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>21:00 - 21:59</td>\n",
       "      <td>40.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529360</th>\n",
       "      <td>263</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>22:00 - 22:59</td>\n",
       "      <td>40.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529361</th>\n",
       "      <td>263</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>23:00 - 23:59</td>\n",
       "      <td>40.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529362 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       zone  weekday    time_binned  Tavg  Tdep  CDD  Precipitation  new_snow  \\\n",
       "0         4  Tuesday  00:00 - 00:59  48.5  13.3  0.0           0.06       0.0   \n",
       "1         4  Tuesday  01:00 - 01:59  48.5  13.3  0.0           0.06       0.0   \n",
       "2         4  Tuesday  02:00 - 02:59  48.5  13.3  0.0           0.06       0.0   \n",
       "3         4  Tuesday  03:00 - 03:59  48.5  13.3  0.0           0.06       0.0   \n",
       "4         4  Tuesday  04:00 - 04:59  48.5  13.3  0.0           0.06       0.0   \n",
       "...     ...      ...            ...   ...   ...  ...            ...       ...   \n",
       "529357  263  Tuesday  19:00 - 19:59  40.5   5.1  0.0           0.02       0.0   \n",
       "529358  263  Tuesday  20:00 - 20:59  40.5   5.1  0.0           0.02       0.0   \n",
       "529359  263  Tuesday  21:00 - 21:59  40.5   5.1  0.0           0.02       0.0   \n",
       "529360  263  Tuesday  22:00 - 22:59  40.5   5.1  0.0           0.02       0.0   \n",
       "529361  263  Tuesday  23:00 - 23:59  40.5   5.1  0.0           0.02       0.0   \n",
       "\n",
       "        snow_depth  trip_time  num_of_taxis  \n",
       "0              0.0       12.0            43  \n",
       "1              0.0       16.0            83  \n",
       "2              0.0       13.0            70  \n",
       "3              0.0       13.0            75  \n",
       "4              0.0       13.0            37  \n",
       "...            ...        ...           ...  \n",
       "529357         0.0       10.0           268  \n",
       "529358         0.0       10.0           388  \n",
       "529359         0.0       10.0           297  \n",
       "529360         0.0       10.0           222  \n",
       "529361         0.0        8.0           165  \n",
       "\n",
       "[529362 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#path\n",
    "path_clean_data='..\\clean database'\n",
    "\n",
    "#load  and merge csv files\n",
    "all_files = glob.glob(path_clean_data + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    print(\"import file: {}\".format(filename))\n",
    "    df = pd.read_csv(filename, index_col=0, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "main_df  = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "main_df = main_df.sort_values(by=['zone','pickup_date','time_binned'])\n",
    "\n",
    "\n",
    "main_df.dropna(inplace=True)\n",
    "main_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "##convert zone feature to string\n",
    "main_df['zone'] = main_df['zone'].astype(str)\n",
    "\n",
    "#\n",
    "\n",
    "main_df.dropna(inplace=True)\n",
    "main_df.drop_duplicates(inplace=True)\n",
    "main_df.drop(['pickup_date', 'trip_distance', 'speed'], axis=1, inplace=True) #drop unneeded features\n",
    "\n",
    "main_df = main_df.drop(['Tmax','Tmin','HDD'], axis=1) #remove features with high correlation\n",
    "\n",
    "main_df['trip_time'] = main_df.trip_time.apply(np.ceil) #round up trip time to nearest integer\n",
    "\n",
    "\n",
    "# main_df = get_dummies(['weekday','time_binned','zone'],main_df) #dummy variables before we split to 3 sets\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#קריאת נתוני מזג האוויר של התקופה הקרובה\n",
    "def getWeather_API_Format_unix():\n",
    "\n",
    "    # Manhattan coordinates\n",
    "    lat =  40.7834\n",
    "    lon = -73.9662\n",
    "\n",
    "    api_key = \"9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&exclude=minutely&appid={api_key}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    Raw_Weather_Data = response.json()\n",
    "    return Raw_Weather_Data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "#ממיר מתאריך ושעה להצפנת מחשב\n",
    "def Convert_DT_To_unix_timestamp(date_request): #convert  '%Y-%m-%d %H:%M:%S to timestamp\n",
    "    \"\"\"Receiving the client's time and date data is in the form\n",
    "    '%Y-%m-%d %H:%M:%S\n",
    "     And this data is converted to the same type\n",
    "    as the ones in the API which are timestamped\n",
    "    \"\"\"\"\"\n",
    "    date_time_obj = datetime.datetime.strptime(date_request, '%Y-%m-%d %H:%M:%S')\n",
    "    unix_timestamp = date_time_obj.timestamp()\n",
    "    Customer_unix_timestamp = int(unix_timestamp)\n",
    "    return Customer_unix_timestamp \n",
    "\n",
    "\n",
    "def weekday_HourBin_method(server_date_input): #return name of weekday\n",
    "    server_date_input = '2022-12-30 17:40'\n",
    "\n",
    "    #convert data to dt type\n",
    "    date_time_obj = datetime.datetime.strptime(server_date_input, '%Y-%m-%d %H:%M')\n",
    "\n",
    "    #create var of day of week for model\n",
    "    day_of_week  = date_time_obj.weekday()\n",
    "    day_names = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "\n",
    "    model_weekDay = day_names[day_of_week]\n",
    "\n",
    "    #create var of time_bin\n",
    "    hours_input = date_time_obj.hour\n",
    "    model_time_bin = f'{hours_input:02}:00 - {hours_input:02}:59'\n",
    "\n",
    "    return (model_weekDay , model_time_bin)\n",
    "\n",
    "\n",
    "def kelvin_to_fahrenheit(temp_kelvin):\n",
    "    #The API temperature data is in Kelvin \n",
    "    #and the temperature data in our model is in Fahrenheit\n",
    "  temp_fahrenheit = 9/5 * (temp_kelvin - 273) + 32\n",
    "  return temp_fahrenheit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[153, 128, 127]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#שימוש בפונקציות ושליפת נתוני מזג האוויר עדכניים לפי תאריך ושעה של הלקוח\n",
    "\n",
    "def Weather_Hourly_Data_For_Model(Weather_Cust_data):\n",
    "    \"\"\"\"Takes time and date data from the client like\n",
    "    '2022-12-30 21:00:00'   \n",
    "    and returns the weather data to the model\"\"\"\n",
    "    \n",
    "    weather_data = getWeather_API_Format_unix()\n",
    "\n",
    "    Weather_Cust_data = '2022-12-30 21:00:00' ###########33##############\n",
    "    dt_API =Convert_DT_To_unix_timestamp(Weather_Cust_data)\n",
    "\n",
    "    # Variables for CDD calculation\n",
    "    threshold_temperature = 291.48 #65 Fahrenheit is 291.48 Calvin\n",
    "    cdd_total = 0\n",
    "\n",
    "    data = weather_data['hourly']\n",
    "    for hourly_data in data:\n",
    "\n",
    "        if hourly_data['dt'] == dt_API:\n",
    "            #calculate Tavg\n",
    "            TempAvg_kelvin = ((hourly_data[\"temp\"]+hourly_data[\"feels_like\"])/2)\n",
    "            Tdep =0\n",
    "            \n",
    "            #calculate CDD\n",
    "            temperature = hourly_data[\"temp\"]\n",
    "            cdd = temperature - threshold_temperature\n",
    "            if cdd > 0:\n",
    "                cdd_total += cdd\n",
    "\n",
    "            #Checking if values ​​exist and inserting data (rain , snow)\n",
    "            if 'rain' in hourly_data:\n",
    "                Precipitation = hourly_data['rain']['1h'] # Precipitation\n",
    "            else:\n",
    "                Precipitation = 0\n",
    "\n",
    "            if 'snow' in hourly_data:\n",
    "                new_snow = hourly_data['snow']['1h'] \n",
    "                snow_dep = hourly_data['snow']['1h'] \n",
    "            else:\n",
    "                new_snow , snow_dep = 0 , 0\n",
    "\n",
    "    TempAvg_f =kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "    return (cdd_total , new_snow ,snow_dep , Precipitation , TempAvg_f , Tdep)\n",
    "\n",
    "\n",
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 152],\n",
    "    \"Central Harlem\": [42, 41],\n",
    "    \"Morningside Heights\": [166],\n",
    "    \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "    \"Central Park\": [43],\n",
    "    \"Spanish Harlem\": [74, 75],\n",
    "    \"Randall's Island\": [194],\n",
    "    \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "    \"Roosevelt Island\": [202],\n",
    "    \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "    \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "    \"Kips Bay\": [137],\n",
    "    \"Stuyvesant Town\": [224],\n",
    "    \"Chelsea\": [246, 68, 90],\n",
    "    \"Flatiron District\": [186],\n",
    "    \"West Village\": [158, 249],\n",
    "    \"Greenwich Village\": [113, 114],\n",
    "    \"East Village\": [79, 4],\n",
    "    \"Soho\": [125, 221, 144],\n",
    "    \"Lower East Side\": [148, 232],\n",
    "    \"Tribeca\": [231],\n",
    "    \"Two Bridges\": [45],\n",
    "    \"Battery Park City\": [13, 12],\n",
    "    \"Financial District\": [209, 261, 87, 88, 12]\n",
    "}\n",
    "\n",
    "zones_to_name_dict['Inwood']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-31 14:14:22.810697\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "# import util\n",
    "\n",
    "import datetime\n",
    "def time_now():\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    return (current_datetime)\n",
    "\n",
    "# app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Friday'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_input():\n",
    "\n",
    "#     zone = request.json['zone']\n",
    "#     date = request.json['date']\n",
    "#     time = request.json['time']\n",
    "\n",
    "#     zone_id = getZoneIDs(zone)\n",
    "#     time_binned = getTimeBinned(time)\n",
    "#     weekday = getWeekDay(date)\n",
    "#     weather_data = getWeather(time)\n",
    "#     return jsonify(setUpModels(zone_id, time_binned, weekday,\n",
    "#                                weather_data, time, date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#קריאת נתוני מזג האוויר של התקופה הקרובה\n",
    "def getWeather_Format_unix():\n",
    "\n",
    "    # Manhattan coordinates\n",
    "    lat =  40.7834\n",
    "    lon = -73.9662\n",
    "\n",
    "    api_key = \"9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&exclude=minutely&appid={api_key}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    Raw_Weather_Data = response.json()\n",
    "\n",
    "    return Raw_Weather_Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "#ממיר מתאריך ושעה להצפנת מחשב\n",
    "def Convert_DT_To_unix_timestamp(date_request): #convert  '%Y-%m-%d %H:%M:%S to timestamp\n",
    "    \"\"\"Receiving the client's time and date data is in the form\n",
    "    '%Y-%m-%d %H:%M:%S\n",
    "     And this data is converted to the same type\n",
    "    as the ones in the API which are timestamped\n",
    "    \"\"\"\"\"\n",
    "    date_time_obj = datetime.datetime.strptime(date_request, '%Y-%m-%d %H:%M:%S')\n",
    "    unix_timestamp = date_time_obj.timestamp()\n",
    "    Customer_unix_timestamp = int(unix_timestamp)\n",
    "    return Customer_unix_timestamp \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getWeekDay(input_date): #return name of weekday\n",
    "    date_client = '2022-12-30 17:40'\n",
    "\n",
    "    #convert data to dt type\n",
    "    date_time_obj = datetime.datetime.strptime(input_date, '%Y-%m-%d %H:%M')\n",
    "\n",
    "    #create var of day of week for model\n",
    "    day_of_week  = date_time_obj.weekday()\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    model_weekDay = day_names[day_of_week]\n",
    "    return model_weekDay\n",
    "\n",
    "def getTimeBinned(input_date):\n",
    "    input_date = '2022-12-30 17:40'\n",
    "    #create var of time_bin\n",
    "    hours_input = input_date.hour\n",
    "    model_time_bin = f'{hours_input:02}:00 - {hours_input:02}:59'\n",
    "\n",
    "    return model_time_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def kelvin_to_fahrenheit(temp_kelvin):\n",
    "    #The API temperature data is in Kelvin \n",
    "    #and the temperature data in our model is in Fahrenheit\n",
    "  temp_fahrenheit = 9/5 * (temp_kelvin - 273) + 32\n",
    "  return temp_fahrenheit\n",
    "\n",
    "\n",
    "  setWeatherData\n",
    "  #שימוש בפונקציות ושליפת נתוני מזג האוויר עדכניים לפי תאריך ושעה של הלקוח\n",
    "\n",
    "def setWeatherData(data_client):\n",
    "    \"\"\"\"Takes time and date data from the client like\n",
    "    '2022-12-30 21:00:00'   \n",
    "    and returns the weather data to the model\"\"\"\n",
    "    \n",
    "    weather_data = getWeather_Format_unix()\n",
    "\n",
    "    data_client = '2022-12-30 21:00:00' ###########33##############\n",
    "    dt_API =Convert_DT_To_unix_timestamp(data_client)\n",
    "\n",
    "    # Variables for CDD calculation\n",
    "    threshold_temperature = 291.48 #65 Fahrenheit is 291.48 Calvin\n",
    "    cdd_total = 0\n",
    "\n",
    "    data = weather_data['hourly']\n",
    "    for hourly_data in data:\n",
    "\n",
    "        if hourly_data['dt'] == dt_API:\n",
    "            #calculate Tavg\n",
    "            TempAvg_kelvin = ((hourly_data[\"temp\"]+hourly_data[\"feels_like\"])/2)\n",
    "            Tdep =0\n",
    "            \n",
    "            #calculate CDD\n",
    "            temperature = hourly_data[\"temp\"]\n",
    "            cdd = temperature - threshold_temperature\n",
    "            if cdd > 0:\n",
    "                cdd_total += cdd\n",
    "\n",
    "            #Checking if values ​​exist and inserting data (rain , snow)\n",
    "            if 'rain' in hourly_data:\n",
    "                Precipitation = hourly_data['rain']['1h'] # Precipitation\n",
    "            else:\n",
    "                Precipitation = 0\n",
    "\n",
    "            if 'snow' in hourly_data:\n",
    "                new_snow = hourly_data['snow']['1h'] \n",
    "                snow_dep = hourly_data['snow']['1h'] \n",
    "            else:\n",
    "                new_snow , snow_dep = 0 , 0\n",
    "\n",
    "    TempAvg_f =kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "    return (cdd_total , new_snow ,snow_dep , Precipitation , TempAvg_f , Tdep)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for time and weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_hours_label(min: int, max: int):\n",
    "    \"\"\" the function creates a list of labels in the format 00:00 - 00:59 for\n",
    "        example\n",
    "\n",
    "    Args:\n",
    "        min (int): min hour (0)\n",
    "        max (int): max hour (24)\n",
    "\n",
    "    Returns:\n",
    "        List: Returns a list of strings ( labels )\n",
    "    \"\"\"\n",
    "    return [f'{s:02d}:00 - {s:02d}:59' for s in range(min, max)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00:00 - 00:59': 0,\n",
       " '01:00 - 01:59': 0,\n",
       " '02:00 - 02:59': 0,\n",
       " '03:00 - 03:59': 0,\n",
       " '04:00 - 04:59': 0,\n",
       " '05:00 - 05:59': 0,\n",
       " '06:00 - 06:59': 0,\n",
       " '07:00 - 07:59': 0,\n",
       " '08:00 - 08:59': 0,\n",
       " '09:00 - 09:59': 0,\n",
       " '10:00 - 10:59': 0,\n",
       " '11:00 - 11:59': 0,\n",
       " '12:00 - 12:59': 0,\n",
       " '13:00 - 13:59': 0,\n",
       " '14:00 - 14:59': 0,\n",
       " '15:00 - 15:59': 0,\n",
       " '16:00 - 16:59': 0,\n",
       " '17:00 - 17:59': 1,\n",
       " '18:00 - 18:59': 0,\n",
       " '19:00 - 19:59': 0,\n",
       " '20:00 - 20:59': 0,\n",
       " '21:00 - 21:59': 0,\n",
       " '22:00 - 22:59': 0,\n",
       " '23:00 - 23:59': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTimeBinned():\n",
    "    input_date = '2022-12-30 17:40'\n",
    "    #create var of time_bin\n",
    "    date_dt = datetime.datetime.strptime(input_date, '%Y-%m-%d %H:%M')\n",
    "    hours_input = str(date_dt.hour)\n",
    "\n",
    "    model_hour_input = f'{hours_input:02}:00 - {hours_input:02}:59'\n",
    "    label_hour_list = get_hours_label(0,24)\n",
    "\n",
    "    # #create dict hour_bin\n",
    "    Dict_hourBin ={}\n",
    "\n",
    "    for label in label_hour_list:\n",
    "        if label == model_hour_input:\n",
    "            Dict_hourBin[label] =1\n",
    "        else:\n",
    "            Dict_hourBin[label] = 0\n",
    "    return Dict_hourBin\n",
    "\n",
    "bin1 = getTimeBinned()\n",
    "bin1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Monday': 0,\n",
       " 'Tuesday': 0,\n",
       " 'Wednesday': 0,\n",
       " 'Thursday': 0,\n",
       " 'Friday': 1,\n",
       " 'Saturday': 0,\n",
       " 'Sunday': 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def getWeekDay(input_date): #return name of weekday\n",
    "#     date_client = '2022-12-30 17:40'\n",
    "\n",
    "#     #convert data to dt type\n",
    "#     date_time_obj = datetime.datetime.strptime(input_date, '%Y-%m-%d %H:%M')\n",
    "\n",
    "#     #create var of day of week for model\n",
    "#     day_of_week  = date_time_obj.weekday()\n",
    "#     day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "#     model_weekDay = day_names[day_of_week]\n",
    "#     return model_weekDay\n",
    "\n",
    "def getWeekDay(input_date):\n",
    "    input_date = '2022-12-30 17:40'\n",
    "\n",
    "    #convert data to dt type\n",
    "    date_time_obj = datetime.datetime.strptime(input_date, '%Y-%m-%d %H:%M')\n",
    "\n",
    "    #create var of day of week for model\n",
    "    day_of_week  = date_time_obj.weekday()\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    model_weekDay_input = day_names[day_of_week]\n",
    "\n",
    "    #create dict\n",
    "    dict_weekday ={}\n",
    "\n",
    "    for every_day in day_names:\n",
    "        if every_day == model_weekDay_input:\n",
    "            dict_weekday[every_day] =1\n",
    "        else:\n",
    "            dict_weekday[every_day] = 0\n",
    "\n",
    "    return dict_weekday\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#קריאת נתוני מזג האוויר של התקופה הקרובה\n",
    "def getWeather_Format_unix():\n",
    "\n",
    "    # Manhattan coordinates\n",
    "    lat =  40.7834\n",
    "    lon = -73.9662\n",
    "\n",
    "    api_key = \"9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&exclude=minutely&appid={api_key}\"\n",
    "    # url = f\"https://api.openweathermap.org/data/2.5/onecall?lat=40.7834&lon=-73.9662&exclude=minutely&appid=9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    Raw_Weather_Data = response.json()\n",
    "\n",
    "    return Raw_Weather_Data\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "#ממיר מתאריך ושעה להצפנת מחשב\n",
    "def Convert_DT_To_unix_timestamp(date_request): #convert  '%Y-%m-%d %H:%M:%S to timestamp\n",
    "    \"\"\"Receiving the client's time and date data is in the form\n",
    "    '%Y-%m-%d %H:%M:%S\n",
    "     And this data is converted to the same type\n",
    "    as the ones in the API which are timestamped\n",
    "    \"\"\"\"\"\n",
    "    date_time_obj = datetime.datetime.strptime(date_request, '%Y-%m-%d %H:%M:%S')\n",
    "    unix_timestamp = date_time_obj.timestamp()\n",
    "    Customer_unix_timestamp = int(unix_timestamp)\n",
    "    return Customer_unix_timestamp \n",
    "\n",
    "def kelvin_to_fahrenheit(temp_kelvin):\n",
    "    #The API temperature data is in Kelvin \n",
    "    #and the temperature data in our model is in Fahrenheit\n",
    "  temp_fahrenheit = 9/5 * (temp_kelvin - 273) + 32\n",
    "  return temp_fahrenheit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeather22(data_client):\n",
    "    \"\"\"\"Takes time and date data from the client like\n",
    "    '2022-12-30 21:00:00'   \n",
    "    and returns the weather data to the model\"\"\"\n",
    "\n",
    "    weather_data_API = getWeather_Format_unix()\n",
    "\n",
    "    data_client = '2022-12-31 22:00:00' ###########33##############\n",
    "    dt_API = 1672527600#Convert_DT_To_unix_timestamp(data_client)\n",
    "\n",
    "    # Variables for CDD calculation\n",
    "    cdd_total = 0\n",
    "\n",
    "    #dict weather\n",
    "    dict_Weather={}\n",
    "\n",
    "    data = weather_data_API['hourly']\n",
    "    result = [hourly_data for hourly_data in data if hourly_data['dt'] == dt_API]\n",
    "    if result:\n",
    "        # calculate Tavg\n",
    "        TempAvg_kelvin = ((result[0][\"temp\"] + result[0][\"feels_like\"]) / 2)\n",
    "        TempAvg_f = kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "        # Tdep\n",
    "        Tdep =0\n",
    "\n",
    "        # calculate CDD\n",
    "        temperature = result[0][\"temp\"]\n",
    "        temperature_fahrenheit = kelvin_to_fahrenheit(temperature)\n",
    "        threshold_temperature_f = 70 # threshold temperature in Fahrenheit\n",
    "        cdd = temperature_fahrenheit - threshold_temperature_f\n",
    "        if cdd > 0:\n",
    "            cdd_total += cdd\n",
    "        \n",
    "        # retrieve rain 1h\n",
    "        rain = result[0][\"rain\"][\"1h\"]\n",
    "\n",
    "        # retrieve snow 1h\n",
    "        if 'snow' in result:\n",
    "            new_snow = result[0][\"snow\"][\"1h\"] \n",
    "            snow_dep = result[0][\"snow\"][\"1h\"] \n",
    "        else:\n",
    "            new_snow , snow_dep = 0 , 0\n",
    "            \n",
    "    return {\n",
    "        'Tavg':TempAvg_f,\n",
    "        'Tdep':Tdep,\n",
    "        'CDD':cdd_total,\n",
    "        'Precipitation':rain,\n",
    "        'new_snow':new_snow,\n",
    "        'snow_depth':snow_dep}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Inwood': [153, 128, 127], 'Washington Heights': [120, 244], 'Upper East Side': 0}\n"
     ]
    }
   ],
   "source": [
    "zone_names_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getZoneIDs(zone_name):\n",
    "    zone_dict = {}\n",
    "    for zone in zone_name:\n",
    "        zone_dict[zone] = zones_to_name_dict[zone]\n",
    "    return zone_dict\n",
    "\n",
    "# def create_dict(zone_name):\n",
    "#     return {zone: 1 for zone in zone_name}\n",
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244]}\n",
    "#     \"Hamilton Heights\": [116, 152],\n",
    "#     \"Central Harlem\": [42, 41],\n",
    "#     \"Morningside Heights\": [166],\n",
    "#     \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "#     \"Central Park\": [43],\n",
    "#     \"Spanish Harlem\": [74, 75],\n",
    "#     \"Randall's Island\": [194],\n",
    "#     \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "#     \"Roosevelt Island\": [202],\n",
    "#     \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "#     \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "#     \"Kips Bay\": [137],\n",
    "#     \"Stuyvesant Town\": [224],\n",
    "#     \"Chelsea\": [246, 68, 90],\n",
    "#     \"Flatiron District\": [186],\n",
    "#     \"West Village\": [158, 249],\n",
    "#     \"Greenwich Village\": [113, 114],\n",
    "#     \"East Village\": [79, 4],\n",
    "#     \"Soho\": [125, 221, 144],\n",
    "#     \"Lower East Side\": [148, 232],\n",
    "#     \"Tribeca\": [231],\n",
    "#     \"Two Bridges\": [45],\n",
    "#     \"Battery Park City\": [13, 12],\n",
    "#     \"Financial District\": [209, 261, 87, 88, 12]\n",
    "# }\n",
    "\n",
    "def getZoneValues(zone_name):\n",
    "    zone_dict = {}\n",
    "    for zone in zone_name:\n",
    "         if zone in zones_to_name_dict:\n",
    "             zone_dict[zone] = zones_to_name_dict[zone]\n",
    "    else:\n",
    "      zone_dict[zone] = 0\n",
    "    return zone_dict\n",
    "\n",
    "zone_names = [\"Inwood\", \"Washington Heights\", \"Upper East Side\"]\n",
    "print(getZoneValues(zone_names)) # {'Inwood': [153, 128, 127], 'Washington Heights': [120, 244], 'Upper East Side': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{153: 1, 128: 1, 127: 1, 120: 0, 244: 0}\n"
     ]
    }
   ],
   "source": [
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244]}\n",
    "zone_names = [\"Inwood\"]\n",
    "\n",
    "\n",
    "def getZones(list_zone_names): #input string on zone_names example zone_list[\"Inwood\"]\n",
    "    # zone_names = [\"Tribeca\",\"Two Bridges\"]\n",
    "    # print(create_dict(zone_names)) \n",
    "    new_dict = {}\n",
    "\n",
    "    #fill the all values of new_dict with 0\n",
    "    #  # can delete it\n",
    "    for key, value in zone_names_dict.items():\n",
    "        for val in value:\n",
    "            new_dict[val] = 0\n",
    "    \n",
    "\n",
    "    # fill with 1 the user zones\n",
    "    for name in list_zone_names:\n",
    "        if name in zones_to_name_dict:\n",
    "            for value in zones_to_name_dict[name]:\n",
    "                new_dict[value] = 1\n",
    "        else:\n",
    "            new_dict[name] = 0\n",
    "    return new_dict  # {153: 1, 128: 1, 127: 1}\n",
    "print(getZones(zone_names)) # {'Inwood': [153, 128, 127], 'Washington Heights': [120, 244], 'Upper East Side': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{153: 1, 128: 1, 127: 1, 120: 1, 244: 1}\n"
     ]
    }
   ],
   "source": [
    "# def convert_dict_to_values(input_dict):\n",
    "#     output_dict = {}\n",
    "#     for key, value in input_dict.items():\n",
    "#         output_dict[value] = 1\n",
    "#     return output_dict\n",
    "\n",
    "zone_names_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244]\n",
    "    # \"Hamilton Heights\": [116, 152]\n",
    "    # \"Central Harlem\": [42, 41],\n",
    "    # \"Morningside Heights\": [166],\n",
    "    # \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "}\n",
    "\n",
    "# output_dict = convert_dict_to_values(zone_names_dict)\n",
    "# print(output_dict)\n",
    "\n",
    "def getDictWithValuesAsKeys(input_dict): # מקבל מילון ומחזיר מילון שהמפתחות שלו זה מספר האיזור עם הערך 1\n",
    "    output_dict = {}\n",
    "    for key, values in input_dict.items():\n",
    "        for value in values:\n",
    "            output_dict[value] = 1\n",
    "    return output_dict\n",
    "\n",
    "print(getDictWithValuesAsKeys(zone_names_dict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getZoneValues(zone_names):\n",
    "#     result = {}\n",
    "#     for zone in zone_names:\n",
    "#         if zone in zone_names_dict:\n",
    "#             result[zone] = 1\n",
    "#         else:\n",
    "#             result[zone] = 0\n",
    "#     return result\n",
    "\n",
    "# zone_names = [\"Inwood\", \"Washington Heights\"]\n",
    "\n",
    "# print(getZoneValues(zone_names)) # {'Inwood': 1, 'Washington Heights': 1, 'Upper East Side': 0}\n",
    "\n",
    "\n",
    "# def get_zones_dict(input_zone_names, zone_names_dict):\n",
    "#     output_dict = {}\n",
    "#     for name in input_zone_names:\n",
    "#         if name in zone_names_dict:\n",
    "#             for key, values in zone_names_dict.items():\n",
    "#                  for value in values:\n",
    "#                     output_dict[value] = 1\n",
    "#         else:\n",
    "#             for key, value in zone_names_dict.items():\n",
    "#                   for val in value:\n",
    "#                       output_dict[val] = 0\n",
    "#     # return new_dict\n",
    "#     return output_dict\n",
    "\n",
    "# x=get_zones_dict(zone_names, zone_names_dict)\n",
    "# x\n",
    "\n",
    "\n",
    "\n",
    "#     # for key, value in zone_names_dict.items():\n",
    "#     #     for val in value:\n",
    "#     #         new_dict[val] = 0\n",
    "#     # return new_dict\n",
    "\n",
    "# zone_names = [\"Inwood\", \"Washington Heights\", \"Upper East Side\"]\n",
    "\n",
    "def get_zones_dict(input_zone_names, zone_names_dict):\n",
    "    output_dict = {}\n",
    "    \n",
    "    for name in input_zone_names: #for every name from the list\n",
    "        if name in zone_names_dict: #if the name in the all zones\n",
    "            for key, values in zone_names_dict.items():\n",
    "                 for value in values:\n",
    "                    output_dict[value] = 1\n",
    "                #  else:\n",
    "                    #  output_dict[name] = 0\n",
    "    return output_dict\n",
    "\n",
    "zone_names = [\"Inwood\"]\n",
    "x=get_zones_dict(zone_names, zone_names_dict)\n",
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 152],\n",
    "    \"Central Harlem\": [42, 41],\n",
    "    \"Morningside Heights\": [166],\n",
    "    \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "    \"Central Park\": [43],\n",
    "    \"Spanish Harlem\": [74, 75],\n",
    "    \"Randall's Island\": [194],\n",
    "    \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "    \"Roosevelt Island\": [202],\n",
    "    \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "    \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "    \"Kips Bay\": [137],\n",
    "    \"Stuyvesant Town\": [224],\n",
    "    \"Chelsea\": [246, 68, 90],\n",
    "    \"Flatiron District\": [186],\n",
    "    \"West Village\": [158, 249],\n",
    "    \"Greenwich Village\": [113, 114],\n",
    "    \"East Village\": [79, 4],\n",
    "    \"Soho\": [125, 221, 144],\n",
    "    \"Lower East Side\": [148, 232],\n",
    "    \"Tribeca\": [231],\n",
    "    \"Two Bridges\": [45],\n",
    "    \"Battery Park City\": [13, 12],\n",
    "    \"Financial District\": [209, 261, 87, 88, 12]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{231: 1, 45: 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 152],\n",
    "    \"Central Harlem\": [42, 41],\n",
    "    \"Morningside Heights\": [166],\n",
    "    \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "    \"Central Park\": [43],\n",
    "    \"Spanish Harlem\": [74, 75],\n",
    "    \"Randall's Island\": [194],\n",
    "    \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "    \"Roosevelt Island\": [202],\n",
    "    \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "    \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "    \"Kips Bay\": [137],\n",
    "    \"Stuyvesant Town\": [224],\n",
    "    \"Chelsea\": [246, 68, 90],\n",
    "    \"Flatiron District\": [186],\n",
    "    \"West Village\": [158, 249],\n",
    "    \"Greenwich Village\": [113, 114],\n",
    "    \"East Village\": [79, 4],\n",
    "    \"Soho\": [125, 221, 144],\n",
    "    \"Lower East Side\": [148, 232],\n",
    "    \"Tribeca\": [231],\n",
    "    \"Two Bridges\": [45],\n",
    "    \"Battery Park City\": [13, 12],\n",
    "    \"Financial District\": [209, 261, 87, 88, 12]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_dict(list_zone_names): #input string on zone_names example zone_list[\"Inwood\"]\n",
    "    new_dict = {}\n",
    "\n",
    "    for name in list_zone_names:\n",
    "        if name in zones_to_name_dict:\n",
    "            for value in zones_to_name_dict[name]:\n",
    "                new_dict[value] = 1\n",
    "        else:\n",
    "            new_dict[name] = 0\n",
    "    return new_dict  # {153: 1, 128: 1, 127: 1}\n",
    "\n",
    "# zone_names = [\"Tribeca\",\"Two Bridges\"]\n",
    "# print(create_dict(zone_names)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-31 23:00:00\n",
      "1672437600.0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Convert the timestamp to a datetime object\n",
    "# date = datetime.datetime.fromtimestamp(1672516800)\n",
    "\n",
    "# Print the date in the desired format\n",
    "# print(date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Convert the timestamp to a datetime object\n",
    "timestamp = 1672520400\n",
    "date = datetime.datetime.fromtimestamp(timestamp)\n",
    "\n",
    "# Print the date\n",
    "print(date)\n",
    "\n",
    "# formatted_date = date.strftime('%d/%m/%Y')\n",
    "# print(formatted_date)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert date string to a datetime object\n",
    "date = datetime.strptime(\"2022-12-31\", \"%Y-%m-%d\")\n",
    "\n",
    "# Convert the datetime object to a timestamp\n",
    "timestamp = time.mktime(date.timetuple())\n",
    "\n",
    "print(timestamp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dt': 1672520400,\n",
       "  'temp': 281.54,\n",
       "  'feels_like': 281.13,\n",
       "  'pressure': 1012,\n",
       "  'humidity': 100,\n",
       "  'dew_point': 281.53,\n",
       "  'uvi': 0,\n",
       "  'clouds': 100,\n",
       "  'visibility': 373,\n",
       "  'wind_speed': 1.36,\n",
       "  'wind_deg': 152,\n",
       "  'wind_gust': 1.37,\n",
       "  'weather': [{'id': 501,\n",
       "    'main': 'Rain',\n",
       "    'description': 'moderate rain',\n",
       "    'icon': '10d'}],\n",
       "  'pop': 1,\n",
       "  'rain': {'1h': 1.12}}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"Takes time and date data from the client like\n",
    "'2022-12-30 21:00:00'   \n",
    "and returns the weather data to the model\"\"\"\n",
    "\n",
    "weather_data = getWeather_Format_unix()\n",
    "\n",
    "Weather_Cust_data = '2022-12-31 21:00:00' ###########33##############\n",
    "dt_API =1672520400#=Convert_DT_To_unix_timestamp(Weather_Cust_data)\n",
    "\n",
    "# Variables for CDD calculation\n",
    "threshold_temperature = 291.48 #65 Fahrenheit is 291.48 Calvin\n",
    "cdd_total = 0\n",
    "\n",
    "data = weather_data['hourly']\n",
    "result = [hourly_data for hourly_data in data if hourly_data['dt'] == dt_API]\n",
    "if result:\n",
    "    # calculate Tavg\n",
    "    TempAvg_kelvin = ((result[0][\"temp\"] + result[0][\"feels_like\"]) / 2)\n",
    "    TempAvg_f = kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "    # calculate Tdep = TempAvg - threshold_temperature\n",
    "    Tdep = 0\n",
    "\n",
    "    # calculate CDD\n",
    "    temperature = result[0][\"temp\"]\n",
    "    cdd = temperature - threshold_temperature\n",
    "    if cdd > 0:\n",
    "        cdd_total += cdd\n",
    "\n",
    "\n",
    "        #     'Tavg':TempAvg_f,Precipitation,\n",
    "#     'Tdep':Tdep,\n",
    "#     'CDD':cdd_total,\n",
    "#     'Precipitation':Precipitation,\n",
    "#     'new_snow':new_snow,\n",
    "#     'snow_depth':snow_dep}\n",
    "        \n",
    "result\n",
    "# TempAvg_f\n",
    "# dt_API\n",
    "# TempAvg_f =kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "threshold_temperature = 70 # threshold temperature in Fahrenheit\n",
    "\n",
    "# convert temperature from Kelvin to Fahrenheit\n",
    "def kelvin_to_fahrenheit(temperature_kelvin):\n",
    "    return (temperature_kelvin - 273.15) * 9/5 + 32\n",
    "\n",
    "# iterate through the data to find the temperature for the given time\n",
    "for hourly_data in data:\n",
    "    if hourly_data['dt'] == dt_API:\n",
    "        # calculate temperature departure\n",
    "        temperature = hourly_data[\"temp\"]\n",
    "        temperature_fahrenheit = kelvin_to_fahrenheit(temperature)\n",
    "        temperature_departure = temperature_fahrenheit - threshold_temperature\n",
    "        print(\"Temperature departure:\", temperature_departure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#שימוש בפונקציות ושליפת נתוני מזג האוויר עדכניים לפי תאריך ושעה של הלקוח\n",
    "\n",
    "def getWeather22(data_client):\n",
    "    \"\"\"\"Takes time and date data from the client like\n",
    "    '2022-12-30 21:00:00'   \n",
    "    and returns the weather data to the model\"\"\"\n",
    "\n",
    "    weather_data_API = getWeather_Format_unix()\n",
    "\n",
    "    data_client = '2022-12-31 22:00:00' ###########33##############\n",
    "    dt_API = 1672527600#Convert_DT_To_unix_timestamp(data_client)\n",
    "\n",
    "    # Variables for CDD calculation\n",
    "    cdd_total = 0\n",
    "\n",
    "    #dict weather\n",
    "    dict_Weather={}\n",
    "\n",
    "    data = weather_data_API['hourly']\n",
    "    result = [hourly_data for hourly_data in data if hourly_data['dt'] == dt_API]\n",
    "    if result:\n",
    "        # calculate Tavg\n",
    "        TempAvg_kelvin = ((result[0][\"temp\"] + result[0][\"feels_like\"]) / 2)\n",
    "        TempAvg_f = kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "        # Tdep\n",
    "        Tdep =0\n",
    "\n",
    "        # calculate CDD\n",
    "        temperature = result[0][\"temp\"]\n",
    "        temperature_fahrenheit = kelvin_to_fahrenheit(temperature)\n",
    "        threshold_temperature_f = 70 # threshold temperature in Fahrenheit\n",
    "        cdd = temperature_fahrenheit - threshold_temperature_f\n",
    "        if cdd > 0:\n",
    "            cdd_total += cdd\n",
    "        \n",
    "        # retrieve rain 1h\n",
    "        rain = result[0][\"rain\"][\"1h\"]\n",
    "\n",
    "        # retrieve snow 1h\n",
    "        if 'snow' in result:\n",
    "            new_snow = result[0][\"snow\"][\"1h\"] \n",
    "            snow_dep = result[0][\"snow\"][\"1h\"] \n",
    "        else:\n",
    "            new_snow , snow_dep = 0 , 0\n",
    "            \n",
    "    return {\n",
    "        'Tavg':TempAvg_f,\n",
    "        'Tdep':Tdep,\n",
    "        'CDD':cdd_total,\n",
    "        'Precipitation':rain,\n",
    "        'new_snow':new_snow,\n",
    "        'snow_depth':snow_dep}\n",
    "\n",
    "\n",
    "\n",
    "# dict_Weather['Tavg']=TempAvg_f\n",
    "# dict_Weather['Tdep']=temperature_departure\n",
    "# dict_Weather['CDD']=cdd_total\n",
    "# dict_Weather['Precipitation']=rain\n",
    "# dict_Weather['new_snow']=new_snow\n",
    "# dict_Weather['snow_depth']=snow_dep\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dict convert to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00:00 - 00:59</th>\n",
       "      <th>01:00 - 01:59</th>\n",
       "      <th>02:00 - 02:59</th>\n",
       "      <th>03:00 - 03:59</th>\n",
       "      <th>04:00 - 04:59</th>\n",
       "      <th>05:00 - 05:59</th>\n",
       "      <th>06:00 - 06:59</th>\n",
       "      <th>07:00 - 07:59</th>\n",
       "      <th>08:00 - 08:59</th>\n",
       "      <th>09:00 - 09:59</th>\n",
       "      <th>...</th>\n",
       "      <th>14:00 - 14:59</th>\n",
       "      <th>15:00 - 15:59</th>\n",
       "      <th>16:00 - 16:59</th>\n",
       "      <th>17:00 - 17:59</th>\n",
       "      <th>18:00 - 18:59</th>\n",
       "      <th>19:00 - 19:59</th>\n",
       "      <th>20:00 - 20:59</th>\n",
       "      <th>21:00 - 21:59</th>\n",
       "      <th>22:00 - 22:59</th>\n",
       "      <th>23:00 - 23:59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00:00 - 00:59  01:00 - 01:59  02:00 - 02:59  03:00 - 03:59  04:00 - 04:59  \\\n",
       "0              0              0              0              0              0   \n",
       "\n",
       "   05:00 - 05:59  06:00 - 06:59  07:00 - 07:59  08:00 - 08:59  09:00 - 09:59  \\\n",
       "0              0              0              0              0              0   \n",
       "\n",
       "   ...  14:00 - 14:59  15:00 - 15:59  16:00 - 16:59  17:00 - 17:59  \\\n",
       "0  ...              0              0              0              1   \n",
       "\n",
       "   18:00 - 18:59  19:00 - 19:59  20:00 - 20:59  21:00 - 21:59  22:00 - 22:59  \\\n",
       "0              0              0              0              0              0   \n",
       "\n",
       "   23:00 - 23:59  \n",
       "0              0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "def getTimeBinned(input_date):\n",
    "    # input_date = '2022-12-30 17:40'\n",
    "    #create var of time_bin\n",
    "    date_dt = datetime.datetime.strptime(input_date, '%Y-%m-%d %H:%M')\n",
    "    hours_input = str(date_dt.hour)\n",
    "\n",
    "    model_hour_input = f'{hours_input:02}:00 - {hours_input:02}:59'\n",
    "    label_hour_list = get_hours_label(0,24)\n",
    "\n",
    "    # #create dict hour_bin\n",
    "    Dict_hourBin ={}\n",
    "\n",
    "    for label in label_hour_list:\n",
    "        if label == model_hour_input:\n",
    "            Dict_hourBin[label] =1\n",
    "        else:\n",
    "            Dict_hourBin[label] = 0\n",
    "    return Dict_hourBin\n",
    "\n",
    "hour_dict = getTimeBinned('2022-12-30 17:40')\n",
    "\n",
    "\n",
    "#convert the hour dict to df\n",
    "hour_df = pd.DataFrame(hour_dict, index=[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-30 17:40'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 152],\n",
    "    \"Central Harlem\": [42, 41],\n",
    "    \"Morningside Heights\": [166],\n",
    "    \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "    \"Central Park\": [43],\n",
    "    \"Spanish Harlem\": [74, 75],\n",
    "    \"Randall's Island\": [194],\n",
    "    \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "    \"Roosevelt Island\": [202],\n",
    "    \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "    \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "    \"Kips Bay\": [137],\n",
    "    \"Stuyvesant Town\": [224],\n",
    "    \"Chelsea\": [246, 68, 90],\n",
    "    \"Flatiron District\": [186],\n",
    "    \"West Village\": [158, 249],\n",
    "    \"Greenwich Village\": [113, 114],\n",
    "    \"East Village\": [79, 4],\n",
    "    \"Soho\": [125, 221, 144],\n",
    "    \"Lower East Side\": [148, 232],\n",
    "    \"Tribeca\": [231],\n",
    "    \"Two Bridges\": [45],\n",
    "    \"Battery Park City\": [13, 12],\n",
    "    \"Financial District\": [209, 261, 87, 88, 12]\n",
    "}\n",
    "\n",
    "def getZones(list_zone_names): #input string on zone_names example zone_list[\"Inwood\"]\n",
    "    # zone_names = [\"Tribeca\",\"Two Bridges\"]\n",
    "    # print(create_dict(zone_names)) \n",
    "    new_dict = {}\n",
    "\n",
    "    #fill the all values of new_dict with 0\n",
    "    #  # can delete it?\n",
    "    # for key, value in zones_to_name_dict.items():\n",
    "    #     for val in value:\n",
    "    #         new_dict[val] = 0\n",
    "    \n",
    "\n",
    "    # fill with 1 the user zones\n",
    "    for name in list_zone_names:\n",
    "        if name in zones_to_name_dict:\n",
    "            for value in zones_to_name_dict[name]:\n",
    "                new_dict[value] = 1\n",
    "        else:\n",
    "            new_dict[name] = 0\n",
    "    return new_dict  # {153: 1, 128: 1, 127: 1}\n",
    "date = '2022-12-30'\n",
    "hours = \"17:40\"\n",
    "total = date +' '+ hours\n",
    "total\n",
    "name = \"2022-12-30 17:40\"\n",
    "name = '2022-12-30 17:40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "# __data_columns = None\n",
    "\n",
    "#input customer\n",
    "def can_delete():\n",
    "    import pandas as pd\n",
    "        \n",
    "    input_time = '15:12'\n",
    "    input_date = '2022-12-30'\n",
    "    full_dt = input_date + ' ' +input_time+':00' #'2022-12-31 22:00:00'\n",
    "    zone_list= ['Tribeca']\n",
    "    zones_dict = getZones(zone_list)\n",
    "    weekday_dict = getWeekDay(input_date)\n",
    "    time_bin_dict =getTimeBinned(input_time)\n",
    "    weather_dict =getWeather(full_dt )\n",
    "\n",
    "    ## merge the all dicts\n",
    "    model_dict = {**zones_dict, **weekday_dict , **time_bin_dict, **weather_dict}\n",
    "\n",
    "    ## convert the dict to dataframe\n",
    "    model_df = pd.DataFrame(model_dict, index=[0])\n",
    "    model_df\n",
    "    return model_df\n",
    "\n",
    "def get_hours_label(min: int, max: int):\n",
    "    \"\"\" the function creates a list of labels in the format 00:00 - 00:59 for\n",
    "        example\n",
    "\n",
    "    Args:\n",
    "        min (int): min hour (0)\n",
    "        max (int): max hour (24)\n",
    "\n",
    "    Returns:\n",
    "        List: Returns a list of strings ( labels )\n",
    "    \"\"\"\n",
    "    return [f'{s:02d}:00 - {s:02d}:59' for s in range(min, max)]\n",
    "\n",
    "\n",
    "def getTimeBinned(input_date):\n",
    "    input_date = '17:40'\n",
    "    #create var of time_bin\n",
    "    date_dt = datetime.datetime.strptime(input_date,'%H:%M')\n",
    "    hours_input = str(date_dt.hour)\n",
    "\n",
    "    model_hour_input = f'{hours_input:02}:00 - {hours_input:02}:59'\n",
    "    label_hour_list = get_hours_label(0,24)\n",
    "\n",
    "    # #create dict hour_bin\n",
    "    Dict_hourBin ={}\n",
    "\n",
    "    for label in label_hour_list:\n",
    "        if label == model_hour_input:\n",
    "            Dict_hourBin[label] =1\n",
    "        else:\n",
    "            Dict_hourBin[label] = 0\n",
    "    return Dict_hourBin\n",
    "\n",
    "def getWeekDay(input_date):\n",
    "    input_date = '2022-12-30'\n",
    "\n",
    "    #convert data to dt type\n",
    "    date_time_obj = datetime.datetime.strptime(input_date, '%Y-%m-%d')\n",
    "\n",
    "    #create var of day of week for model\n",
    "    day_of_week  = date_time_obj.weekday()\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    model_weekDay_input = day_names[day_of_week]\n",
    "\n",
    "    #create dict\n",
    "    dict_weekday ={}\n",
    "\n",
    "    for every_day in day_names:\n",
    "        if every_day == model_weekDay_input:\n",
    "            dict_weekday[every_day] =1\n",
    "        else:\n",
    "            dict_weekday[every_day] = 0\n",
    "\n",
    "    return dict_weekday\n",
    "\n",
    "\n",
    "#קריאת נתוני מזג האוויר של התקופה הקרובה\n",
    "def getWeather_Format_unix():\n",
    "\n",
    "    # Manhattan coordinates\n",
    "    lat =  40.7834\n",
    "    lon = -73.9662\n",
    "\n",
    "    api_key = \"9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&exclude=minutely&appid={api_key}\"\n",
    "    # url = f\"https://api.openweathermap.org/data/2.5/onecall?lat=40.7834&lon=-73.9662&exclude=minutely&appid=9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    Raw_Weather_Data = response.json()\n",
    "\n",
    "    return Raw_Weather_Data\n",
    "\n",
    "#ממיר מתאריך ושעה להצפנת מחשב\n",
    "def Convert_DT_To_unix_timestamp(date_request): #convert  '%Y-%m-%d %H:%M:%S to timestamp\n",
    "    \"\"\"Receiving the client's time and date data is in the form\n",
    "    '%Y-%m-%d %H:%M:%S\n",
    "     And this data is converted to the same type\n",
    "    as the ones in the API which are timestamped\n",
    "    \"\"\"\"\"\n",
    "    date_time_obj = datetime.datetime.strptime(date_request, '%Y-%m-%d %H:%M:%S')\n",
    "    unix_timestamp = date_time_obj.timestamp()\n",
    "    Customer_unix_timestamp = int(unix_timestamp)\n",
    "    return Customer_unix_timestamp \n",
    "\n",
    "def kelvin_to_fahrenheit(temp_kelvin):\n",
    "    #The API temperature data is in Kelvin \n",
    "    #and the temperature data in our model is in Fahrenheit\n",
    "  temp_fahrenheit = 9/5 * (temp_kelvin - 273) + 32\n",
    "  return temp_fahrenheit\n",
    "\n",
    "\n",
    "def getWeather(data_client):\n",
    "    \"\"\"\"Takes time and date data from the client like\n",
    "    '2022-12-30 21:00:00'   \n",
    "    and returns the weather data to the model\"\"\"\n",
    "\n",
    "    weather_data_API = getWeather_Format_unix()\n",
    "\n",
    "    data_client = '2022-12-31 22:00:00' ###########33##############\n",
    "    dt_API = Convert_DT_To_unix_timestamp(data_client) #1672527600\n",
    "\n",
    "    global Tdep\n",
    "    global TempAvg_f\n",
    "    global cdd_total\n",
    "    global rain\n",
    "    global new_snow\n",
    "    global snow_dep\n",
    "\n",
    "    # Variables for CDD calculation\n",
    "    cdd_total = 0\n",
    "\n",
    "\n",
    "\n",
    "    data = weather_data_API['hourly']\n",
    "    result = [hourly_data for hourly_data in data if hourly_data['dt'] == dt_API]\n",
    "    if result:\n",
    "        # calculate Tavg\n",
    "        TempAvg_kelvin = ((result[0][\"temp\"] + result[0][\"feels_like\"]) / 2)\n",
    "        TempAvg_f = kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "        # Tdep\n",
    "        Tdep =0\n",
    "\n",
    "        # calculate CDD\n",
    "        temperature = result[0][\"temp\"]\n",
    "        temperature_fahrenheit = kelvin_to_fahrenheit(temperature)\n",
    "        threshold_temperature_f = 70 # threshold temperature in Fahrenheit\n",
    "        cdd = temperature_fahrenheit - threshold_temperature_f\n",
    "        if cdd > 0:\n",
    "            cdd_total += cdd\n",
    "        \n",
    "        # retrieve rain 1h\n",
    "        if 'rain' in result:\n",
    "          rain = result[0][\"rain\"][\"1h\"]\n",
    "        else:\n",
    "         rain =0\n",
    "\n",
    "        # retrieve snow 1h\n",
    "        if 'snow' in result:\n",
    "            new_snow = result[0][\"snow\"][\"1h\"] \n",
    "            snow_dep = result[0][\"snow\"][\"1h\"] \n",
    "        else:\n",
    "            new_snow , snow_dep = 0 , 0\n",
    "            \n",
    "    return {\n",
    "        'Tavg':TempAvg_f,\n",
    "        'Tdep':Tdep,\n",
    "        'CDD':cdd_total,\n",
    "        'Precipitation':rain,\n",
    "        'new_snow':new_snow,\n",
    "        'snow_depth':snow_dep}\n",
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 152],\n",
    "    \"Central Harlem\": [42, 41],\n",
    "    \"Morningside Heights\": [166],\n",
    "    \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "    \"Central Park\": [43],\n",
    "    \"Spanish Harlem\": [74, 75],\n",
    "    \"Randall's Island\": [194],\n",
    "    \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "    \"Roosevelt Island\": [202],\n",
    "    \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "    \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "    \"Kips Bay\": [137],\n",
    "    \"Stuyvesant Town\": [224],\n",
    "    \"Chelsea\": [246, 68, 90],\n",
    "    \"Flatiron District\": [186],\n",
    "    \"West Village\": [158, 249],\n",
    "    \"Greenwich Village\": [113, 114],\n",
    "    \"East Village\": [79, 4],\n",
    "    \"Soho\": [125, 221, 144],\n",
    "    \"Lower East Side\": [148, 232],\n",
    "    \"Tribeca\": [231],\n",
    "    \"Two Bridges\": [45],\n",
    "    \"Battery Park City\": [13, 12],\n",
    "    \"Financial District\": [209, 261, 87, 88, 12]\n",
    "}\n",
    "\n",
    "\n",
    "def getZones(list_zone_names): #input string on zone_names example zone_list[\"Inwood\"]\n",
    "    # zone_names = [\"Tribeca\",\"Two Bridges\"]\n",
    "    # print(create_dict(zone_names)) \n",
    "    new_dict_int = {}\n",
    "    new_dict_string ={}\n",
    "\n",
    "    #fill the all values of new_dict with 0\n",
    "    #  # can delete it?\n",
    "    for key, value in zones_to_name_dict.items():\n",
    "        for val in value:\n",
    "            new_dict_int[val] = 0\n",
    "    \n",
    "\n",
    "    # fill with 1 the user zones\n",
    "    for name in list_zone_names:\n",
    "        if name in zones_to_name_dict:\n",
    "            for value in zones_to_name_dict[name]:\n",
    "                new_dict_int[value] = 1\n",
    "\n",
    "    \n",
    "    # #convert dtypes keys from int to string\n",
    "    for key, value in new_dict_int.items():\n",
    "        new_key = str(key)\n",
    "        new_dict_string[new_key] = value\n",
    "    \n",
    "\n",
    "    return new_dict_string  # {153: 1, 128: 1, 127: 1}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_features_input(time):\n",
    "    # zone = requests.json['zone'] #user give list of string\n",
    "    # date = request.json['date']\n",
    "    # time = requests.json['time']\n",
    "    # time = '2022-12-30 17:40'\n",
    "\n",
    "    # zone_id = getZones(zone)\n",
    "    time_binned = getTimeBinned(time)\n",
    "    return time_binned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# def load_saved_artifacts():\n",
    "    # return print(\"loading saved artifacts..start\")\n",
    "    # global __data_columns\n",
    "    \n",
    "    # with open(\"./artifacts/columns.json\",'r') as f:\n",
    "        # __data_columns =json.load(f)['data_columns']\n",
    "\n",
    "    \n",
    "    # return print(\"Loaded the features\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    # print(\"we started python Flask for my model\")\n",
    "    # server.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge the all dicts\n",
    "# model_dict = {**zone_dict, **weekday_dict , **timeBin_dict, **weather_dict}\n",
    "## convert the dict to dataframe\n",
    "# model_df = pd.DataFrame(zone_dict, index=[0])\n",
    "\n",
    "input_time = '15:12'\n",
    "input_date = '2022-12-30'\n",
    "full_dt = input_date + ' ' +input_time+':00' #'2022-12-31 22:00:00'\n",
    "zone_list= ['Tribeca']\n",
    "zones_dict = getZones(zone_list)\n",
    "weekday_dict = getWeekDay(input_date)\n",
    "time_bin_dict =getTimeBinned(input_time)\n",
    "weather_dict =getWeather(full_dt )\n",
    "\n",
    "## merge the all dicts\n",
    "feature_input_dict = {**zones_dict, **weekday_dict , **time_bin_dict, **weather_dict}\n",
    "\n",
    "## convert the dict to dataframe\n",
    "# model_df = pd.DataFrame(model_dict, index=[0])\n",
    "# model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'153': 0,\n",
       " '128': 0,\n",
       " '127': 0,\n",
       " '120': 0,\n",
       " '244': 0,\n",
       " '116': 0,\n",
       " '152': 0,\n",
       " '42': 0,\n",
       " '41': 0,\n",
       " '166': 0,\n",
       " '24': 0,\n",
       " '151': 0,\n",
       " '238': 0,\n",
       " '239': 0,\n",
       " '143': 0,\n",
       " '142': 0,\n",
       " '43': 0,\n",
       " '74': 0,\n",
       " '75': 0,\n",
       " '194': 0,\n",
       " '236': 0,\n",
       " '263': 0,\n",
       " '262': 0,\n",
       " '237': 0,\n",
       " '141': 0,\n",
       " '140': 0,\n",
       " '202': 0,\n",
       " '50': 0,\n",
       " '48': 0,\n",
       " '163': 0,\n",
       " '230': 0,\n",
       " '161': 0,\n",
       " '100': 0,\n",
       " '164': 0,\n",
       " '170': 0,\n",
       " '162': 0,\n",
       " '229': 0,\n",
       " '233': 0,\n",
       " '137': 0,\n",
       " '224': 0,\n",
       " '246': 0,\n",
       " '68': 0,\n",
       " '90': 0,\n",
       " '186': 0,\n",
       " '158': 0,\n",
       " '249': 0,\n",
       " '113': 0,\n",
       " '114': 0,\n",
       " '79': 0,\n",
       " '4': 0,\n",
       " '125': 0,\n",
       " '221': 0,\n",
       " '144': 0,\n",
       " '148': 0,\n",
       " '232': 0,\n",
       " '231': 1,\n",
       " '45': 0,\n",
       " '13': 0,\n",
       " '12': 0,\n",
       " '209': 0,\n",
       " '261': 0,\n",
       " '87': 0,\n",
       " '88': 0,\n",
       " 'Monday': 0,\n",
       " 'Tuesday': 0,\n",
       " 'Wednesday': 0,\n",
       " 'Thursday': 0,\n",
       " 'Friday': 1,\n",
       " 'Saturday': 0,\n",
       " 'Sunday': 0,\n",
       " '00:00 - 00:59': 0,\n",
       " '01:00 - 01:59': 0,\n",
       " '02:00 - 02:59': 0,\n",
       " '03:00 - 03:59': 0,\n",
       " '04:00 - 04:59': 0,\n",
       " '05:00 - 05:59': 0,\n",
       " '06:00 - 06:59': 0,\n",
       " '07:00 - 07:59': 0,\n",
       " '08:00 - 08:59': 0,\n",
       " '09:00 - 09:59': 0,\n",
       " '10:00 - 10:59': 0,\n",
       " '11:00 - 11:59': 0,\n",
       " '12:00 - 12:59': 0,\n",
       " '13:00 - 13:59': 0,\n",
       " '14:00 - 14:59': 0,\n",
       " '15:00 - 15:59': 0,\n",
       " '16:00 - 16:59': 0,\n",
       " '17:00 - 17:59': 1,\n",
       " '18:00 - 18:59': 0,\n",
       " '19:00 - 19:59': 0,\n",
       " '20:00 - 20:59': 0,\n",
       " '21:00 - 21:59': 0,\n",
       " '22:00 - 22:59': 0,\n",
       " '23:00 - 23:59': 0,\n",
       " 'Tavg': 46.55299999999996,\n",
       " 'Tdep': 0,\n",
       " 'CDD': 0,\n",
       " 'Precipitation': 10,\n",
       " 'new_snow': 0,\n",
       " 'snow_depth': 0}"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# input_time = '15:12'\n",
    "# input_date = '2022-12-30'\n",
    "# full_dt = input_date + ' ' +input_time+':00' #'2022-12-31 22:00:00'\n",
    "# zones_dict = getZones(\"Tribeca\")\n",
    "# weekday_dict = getWeekDay(input_date)\n",
    "# time_bin_dict =getTimeBinned(input_time)\n",
    "# weather_dict =getWeather(full_dt )\n",
    "# model_dict\n",
    "# # model_df = pd.DataFrame(zones_dict, index=[0])\n",
    "# # model_df\n",
    "\n",
    "\n",
    "len(feature_input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100': 0,\n",
       " '107': 0,\n",
       " '113': 0,\n",
       " '114': 0,\n",
       " '116': 0,\n",
       " '12': 0,\n",
       " '120': 0,\n",
       " '125': 0,\n",
       " '127': 0,\n",
       " '128': 0,\n",
       " '13': 0,\n",
       " '137': 0,\n",
       " '140': 0,\n",
       " '141': 0,\n",
       " '142': 0,\n",
       " '143': 0,\n",
       " '144': 0,\n",
       " '148': 0,\n",
       " '151': 0,\n",
       " '152': 0,\n",
       " '153': 0,\n",
       " '158': 0,\n",
       " '161': 0,\n",
       " '162': 0,\n",
       " '163': 0,\n",
       " '164': 0,\n",
       " '166': 0,\n",
       " '170': 0,\n",
       " '186': 0,\n",
       " '194': 0,\n",
       " '202': 0,\n",
       " '209': 0,\n",
       " '211': 0,\n",
       " '224': 0,\n",
       " '229': 0,\n",
       " '230': 0,\n",
       " '231': 0,\n",
       " '232': 0,\n",
       " '233': 0,\n",
       " '234': 0,\n",
       " '236': 0,\n",
       " '237': 0,\n",
       " '238': 0,\n",
       " '239': 0,\n",
       " '24': 0,\n",
       " '243': 0,\n",
       " '244': 0,\n",
       " '246': 0,\n",
       " '249': 0,\n",
       " '261': 0,\n",
       " '262': 0,\n",
       " '263': 0,\n",
       " '4': 0,\n",
       " '41': 0,\n",
       " '42': 0,\n",
       " '43': 0,\n",
       " '45': 0,\n",
       " '48': 0,\n",
       " '50': 0,\n",
       " '68': 0,\n",
       " '74': 0,\n",
       " '75': 0,\n",
       " '79': 0,\n",
       " '87': 0,\n",
       " '88': 0,\n",
       " '90': 0,\n",
       " '00:00 - 00:59': 0,\n",
       " '01:00 - 01:59': 0,\n",
       " '02:00 - 02:59': 0,\n",
       " '03:00 - 03:59': 0,\n",
       " '04:00 - 04:59': 0,\n",
       " '05:00 - 05:59': 0,\n",
       " '06:00 - 06:59': 0,\n",
       " '07:00 - 07:59': 0,\n",
       " '08:00 - 08:59': 0,\n",
       " '09:00 - 09:59': 0,\n",
       " '10:00 - 10:59': 0,\n",
       " '11:00 - 11:59': 0,\n",
       " '12:00 - 12:59': 0,\n",
       " '13:00 - 13:59': 0,\n",
       " '14:00 - 14:59': 0,\n",
       " '15:00 - 15:59': 0,\n",
       " '16:00 - 16:59': 0,\n",
       " '17:00 - 17:59': 0,\n",
       " '18:00 - 18:59': 0,\n",
       " '19:00 - 19:59': 0,\n",
       " '20:00 - 20:59': 0,\n",
       " '21:00 - 21:59': 0,\n",
       " '22:00 - 22:59': 0,\n",
       " '23:00 - 23:59': 0,\n",
       " 'friday': 0,\n",
       " 'monday': 0,\n",
       " 'saturday': 0,\n",
       " 'sunday': 0,\n",
       " 'thursday': 0,\n",
       " 'tuesday': 0,\n",
       " 'wednesday': 0,\n",
       " 'tavg': 0,\n",
       " 'tdep': 0,\n",
       " 'cdd': 0,\n",
       " 'precipitation': 0,\n",
       " 'new_snow': 0,\n",
       " 'snow_depth': 0,\n",
       " 'trip_time': 0}"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# # Open the JSON file\n",
    "# with open('columns.json', 'r') as f:\n",
    "#     # Load the JSON data\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Access the values in the data_columns key of the dictionary\n",
    "# columns = data['data_columns']\n",
    "# columns\n",
    "# # Assign the value 1 to each element in the columns list\n",
    "# # for column in columns:\n",
    "#     # column = 1\n",
    "\n",
    "\n",
    "import json\n",
    "def json_columns_dict0():\n",
    "    with open(\"..\\columns.json\", \"r\") as f:\n",
    "        data_columns = json.load(f)\n",
    "\n",
    "    data_column_dict_0 = {}\n",
    "    for column in data_columns[\"data_columns\"]:\n",
    "        data_column_dict_0[column] = 0 #filling the columons value with 0\n",
    "\n",
    "    return data_column_dict_0\n",
    "\n",
    "# print(column_dict) # {'100': 0, '107': 0, '113': 0, '114': 0}\n",
    "data_column_dict_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_column_dict.update(feature_input_dict)\n",
    "# len(data_column_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are duplicate values in the dictionary.\n"
     ]
    }
   ],
   "source": [
    "zones_dict\n",
    "\n",
    "\n",
    " \n",
    "def check_duplicate_values(dictionary):\n",
    "  values = []\n",
    "  for value in dictionary.items():\n",
    "    values.append(value[1])\n",
    "  return len(values) != len(set(values))\n",
    "\n",
    "\n",
    "if check_duplicate_values(zones_dict):\n",
    "  print(\"There are duplicate values in the dictionary.\")\n",
    "else:\n",
    "  print(\"There are no duplicate values in the dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are duplicate values in the dictionary: [127].\n"
     ]
    }
   ],
   "source": [
    "def check_duplicate_values(dictionary):\n",
    "  values = []\n",
    "  duplicate_values = []\n",
    "  for value in dictionary.values():\n",
    "    values.extend(value)\n",
    "  for value in set(values):\n",
    "    if values.count(value) > 1:\n",
    "      duplicate_values.append(value)\n",
    "  return duplicate_values\n",
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 127]}\n",
    "\n",
    "duplicate_values = check_duplicate_values(zones_to_name_dict)\n",
    "if duplicate_values:\n",
    "  print(f\"There are duplicate values in the dictionary: {duplicate_values}.\")\n",
    "else:\n",
    "  print(\"There are no duplicate values in the dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "# __data_columns = None\n",
    "\n",
    "\n",
    "\n",
    "def json_columns_dict0(): # step 2\n",
    "    #filling the json columons value with 0 and return dict\n",
    "    with open(\"..\\columns.json\", \"r\") as f:\n",
    "        data_columns = json.load(f)\n",
    "\n",
    "    data_column_dict_0 = {}\n",
    "    for column in data_columns[\"data_columns\"]:\n",
    "        data_column_dict_0[column] = 0 \n",
    "\n",
    "    return data_column_dict_0\n",
    "\n",
    "\n",
    "def update_dict_values(main_dict, sec_dict): # step 3\n",
    "  #Returns a dictionary with the keys in the main dictionary and with the values ​​of sec_dict\n",
    "  # input main_dict= {\"Avi\":0 ,\"Beth\":0 ,\"Gamil\":0}\n",
    "  # input sec_dict ={\"Noam\":12 ,\"Beth\":2,\"Avi\":1 }\n",
    "  # output {'Avi': 1, 'Beth': 2, 'Gamil': 0}\n",
    "  \n",
    "  updated_main_dict = {}\n",
    "  for key in main_dict:\n",
    "    if key in sec_dict:\n",
    "      updated_main_dict[key] = sec_dict[key]\n",
    "    else:\n",
    "      updated_main_dict[key] = main_dict[key]\n",
    "  return updated_main_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#input features\n",
    "def input_feature_values(zone_list,input_date,input_time,full_dt): #step 1\n",
    "    import pandas as pd\n",
    "        #example of inputs\n",
    "    # input_time = '15:12'\n",
    "    # input_date = '2022-12-30'\n",
    "    # full_dt = input_date + ' ' +input_time+':00' #'2022-12-31 22:00:00'\n",
    "    # zone_list= ['Tribeca']\n",
    "    zones_dict = getZones(zone_list)\n",
    "    weekday_dict = getWeekDay(input_date)\n",
    "    time_bin_dict =getTimeBinned(input_time)\n",
    "    weather_dict =getWeather(full_dt )\n",
    "\n",
    "    ## merge the all dicts\n",
    "    feature_input_dict = {**zones_dict, **weekday_dict , **time_bin_dict, **weather_dict}\n",
    "\n",
    "    #lower dict keys\n",
    "    feature_input_dict = lower_dict_keys(feature_input_dict)\n",
    "\n",
    "    #import the json columons and fill with values 0\n",
    "    json_columons =json_columns_dict0()\n",
    "\n",
    "    #create the dict with all sample of coulmons\n",
    "    model_sample_dict = update_dict_values(json_columons,feature_input_dict)\n",
    "\n",
    "    ## convert the dict to dataframe\n",
    "    model_sample_df = pd.DataFrame(model_sample_dict, index=[0])\n",
    "    return model_sample_df\n",
    "\n",
    "\n",
    "def lower_dict_keys(dictionary): #lower dict keys\n",
    "    lower_dict = {}\n",
    "    for key in dictionary:\n",
    "        lower_key = key.lower()\n",
    "        lower_dict[lower_key] = dictionary[key]\n",
    "    return lower_dict\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "def get_hours_label(min: int, max: int):\n",
    "    \"\"\" the function creates a list of labels in the format 00:00 - 00:59 for\n",
    "        example\n",
    "\n",
    "    Args:\n",
    "        min (int): min hour (0)\n",
    "        max (int): max hour (24)\n",
    "\n",
    "    Returns:\n",
    "        List: Returns a list of strings ( labels )\n",
    "    \"\"\"\n",
    "    return [f'{s:02d}:00 - {s:02d}:59' for s in range(min, max)]\n",
    "\n",
    "\n",
    "def getTimeBinned(input_date):\n",
    "    input_date = '17:40'\n",
    "    #create var of time_bin\n",
    "    date_dt = datetime.datetime.strptime(input_date,'%H:%M')\n",
    "    hours_input = str(date_dt.hour)\n",
    "\n",
    "    model_hour_input = f'{hours_input:02}:00 - {hours_input:02}:59'\n",
    "    label_hour_list = get_hours_label(0,24)\n",
    "\n",
    "    # #create dict hour_bin\n",
    "    Dict_hourBin ={}\n",
    "\n",
    "    for label in label_hour_list:\n",
    "        if label == model_hour_input:\n",
    "            Dict_hourBin[label] =1\n",
    "        else:\n",
    "            Dict_hourBin[label] = 0\n",
    "    return Dict_hourBin\n",
    "\n",
    "def getWeekDay(input_date):\n",
    "    input_date = '2022-12-30'\n",
    "\n",
    "    #convert data to dt type\n",
    "    date_time_obj = datetime.datetime.strptime(input_date, '%Y-%m-%d')\n",
    "\n",
    "    #create var of day of week for model\n",
    "    day_of_week  = date_time_obj.weekday()\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    model_weekDay_input = day_names[day_of_week]\n",
    "\n",
    "    #create dict\n",
    "    dict_weekday ={}\n",
    "\n",
    "    for every_day in day_names:\n",
    "        if every_day == model_weekDay_input:\n",
    "            dict_weekday[every_day] =1\n",
    "        else:\n",
    "            dict_weekday[every_day] = 0\n",
    "\n",
    "    return dict_weekday\n",
    "\n",
    "\n",
    "#קריאת נתוני מזג האוויר של התקופה הקרובה\n",
    "def getWeather_Format_unix():\n",
    "\n",
    "    # Manhattan coordinates\n",
    "    lat =  40.7834\n",
    "    lon = -73.9662\n",
    "\n",
    "    api_key = \"9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&exclude=minutely&appid={api_key}\"\n",
    "    # url = f\"https://api.openweathermap.org/data/2.5/onecall?lat=40.7834&lon=-73.9662&exclude=minutely&appid=9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    Raw_Weather_Data = response.json()\n",
    "\n",
    "    return Raw_Weather_Data\n",
    "\n",
    "#ממיר מתאריך ושעה להצפנת מחשב\n",
    "def Convert_DT_To_unix_timestamp(date_request): #convert  '%Y-%m-%d %H:%M:%S to timestamp\n",
    "    \"\"\"Receiving the client's time and date data is in the form\n",
    "    '%Y-%m-%d %H:%M:%S\n",
    "     And this data is converted to the same type\n",
    "    as the ones in the API which are timestamped\n",
    "    \"\"\"\"\"\n",
    "    date_time_obj = datetime.datetime.strptime(date_request, '%Y-%m-%d %H:%M:%S')\n",
    "    unix_timestamp = date_time_obj.timestamp()\n",
    "    Customer_unix_timestamp = int(unix_timestamp)\n",
    "    return Customer_unix_timestamp \n",
    "\n",
    "def kelvin_to_fahrenheit(temp_kelvin):\n",
    "    #The API temperature data is in Kelvin \n",
    "    #and the temperature data in our model is in Fahrenheit\n",
    "  temp_fahrenheit = 9/5 * (temp_kelvin - 273) + 32\n",
    "  return temp_fahrenheit\n",
    "\n",
    "\n",
    "def getWeather(data_client):\n",
    "    \"\"\"\"Takes time and date data from the client like\n",
    "    '2022-12-30 21:00:00'   \n",
    "    and returns the weather data to the model\"\"\"\n",
    "\n",
    "    weather_data_API = getWeather_Format_unix()\n",
    "\n",
    "    data_client = '2022-12-31 22:00:00' ###########33##############\n",
    "    # dt_API = Convert_DT_To_unix_timestamp(data_client) #1672527600\n",
    "    dt_API = 1672657200\n",
    "\n",
    "    global Tdep\n",
    "    global TempAvg_f\n",
    "    global cdd_total\n",
    "    global rain\n",
    "    global new_snow\n",
    "    global snow_dep\n",
    "\n",
    "    # Variables for CDD calculation\n",
    "    cdd_total = 0\n",
    "\n",
    "\n",
    "\n",
    "    data = weather_data_API['hourly']\n",
    "    result = [hourly_data for hourly_data in data if hourly_data['dt'] == dt_API]\n",
    "    if result:\n",
    "        # calculate Tavg\n",
    "        TempAvg_kelvin = ((result[0][\"temp\"] + result[0][\"feels_like\"]) / 2)\n",
    "        TempAvg_f = kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "        # Tdep\n",
    "        Tdep =0\n",
    "\n",
    "        # calculate CDD\n",
    "        temperature = result[0][\"temp\"]\n",
    "        temperature_fahrenheit = kelvin_to_fahrenheit(temperature)\n",
    "        threshold_temperature_f = 70 # threshold temperature in Fahrenheit\n",
    "        cdd = temperature_fahrenheit - threshold_temperature_f\n",
    "        if cdd > 0:\n",
    "            cdd_total += cdd\n",
    "        \n",
    "        # retrieve rain 1h\n",
    "        if 'rain' in result:\n",
    "          rain = result[0][\"rain\"][\"1h\"]\n",
    "        else:\n",
    "         rain =0\n",
    "\n",
    "        # retrieve snow 1h\n",
    "        if 'snow' in result:\n",
    "            new_snow = result[0][\"snow\"][\"1h\"] \n",
    "            snow_dep = result[0][\"snow\"][\"1h\"] \n",
    "        else:\n",
    "            new_snow , snow_dep = 0 , 0\n",
    "            \n",
    "    return {\n",
    "        'Tavg':TempAvg_f,\n",
    "        'Tdep':Tdep,\n",
    "        'CDD':cdd_total,\n",
    "        'Precipitation':rain,\n",
    "        'new_snow':new_snow,\n",
    "        'snow_depth':snow_dep}\n",
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 152],\n",
    "    \"Central Harlem\": [42, 41],\n",
    "    \"Morningside Heights\": [166],\n",
    "    \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "    \"Central Park\": [43],\n",
    "    \"Spanish Harlem\": [74, 75],\n",
    "    \"Randall's Island\": [194],\n",
    "    \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "    \"Roosevelt Island\": [202],\n",
    "    \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "    \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "    \"Kips Bay\": [137],\n",
    "    \"Stuyvesant Town\": [224],\n",
    "    \"Chelsea\": [246, 68, 90],\n",
    "    \"Flatiron District\": [186],\n",
    "    \"West Village\": [158, 249],\n",
    "    \"Greenwich Village\": [113, 114],\n",
    "    \"East Village\": [79, 4],\n",
    "    \"Soho\": [125, 221, 144],\n",
    "    \"Lower East Side\": [148, 232],\n",
    "    \"Tribeca\": [231],\n",
    "    \"Two Bridges\": [45],\n",
    "    \"Battery Park City\": [13, 12],\n",
    "    \"Financial District\": [209, 261, 87, 88, 12]\n",
    "}\n",
    "\n",
    "\n",
    "def getZones(list_zone_names): #input string on zone_names example zone_list[\"Inwood\"]\n",
    "    # zone_names = [\"Tribeca\",\"Two Bridges\"]\n",
    "    # print(create_dict(zone_names)) \n",
    "    new_dict_int = {}\n",
    "    new_dict_string ={}\n",
    "    \n",
    "    # fill with 1 the user zones\n",
    "    for name in list_zone_names:\n",
    "        if name in zones_to_name_dict:\n",
    "            for value in zones_to_name_dict[name]:\n",
    "                new_dict_int[value] = 1\n",
    "\n",
    "    \n",
    "    # #convert dtypes keys from int to string\n",
    "    for key, value in new_dict_int.items():\n",
    "        new_key = str(key)\n",
    "        new_dict_string[new_key] = value\n",
    "    \n",
    "\n",
    "    return new_dict_string  # {153: 1, 128: 1, 127: 1}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_features_input(time):\n",
    "    # zone = requests.json['zone'] #user give list of string\n",
    "    # date = request.json['date']\n",
    "    # time = requests.json['time']\n",
    "    # time = '2022-12-30 17:40'\n",
    "\n",
    "    # zone_id = getZones(zone)\n",
    "    time_binned = getTimeBinned(time)\n",
    "    return time_binned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# def load_saved_artifacts():\n",
    "    # return print(\"loading saved artifacts..start\")\n",
    "    # global __data_columns\n",
    "    \n",
    "    # with open(\"./artifacts/columns.json\",'r') as f:\n",
    "        # __data_columns =json.load(f)['data_columns']\n",
    "\n",
    "    \n",
    "    # return print(\"Loaded the features\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    # print(\"we started python Flask for my model\")\n",
    "    # server.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>107</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>116</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>125</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>...</th>\n",
       "      <th>sunday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tdep</th>\n",
       "      <th>cdd</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>new_snow</th>\n",
       "      <th>snow_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   100  107  113  114  116  12  120  125  127  128  ...  sunday  thursday  \\\n",
       "0    0    0    0    0    0   0    0    0    0    0  ...       0         0   \n",
       "\n",
       "   tuesday  wednesday    tavg  tdep  cdd  precipitation  new_snow  snow_depth  \n",
       "0        0          0  41.999     0    0              0         0           0  \n",
       "\n",
       "[1 rows x 103 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "import pickle\n",
    "# __data_columns = None\n",
    "__model = None\n",
    "\n",
    "def get_model():\n",
    "    if __model is None:\n",
    "        with open('taxi_project_model.pickle', 'rb') as f:\n",
    "            __model = pickle.load(f)\n",
    "    return __model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def json_columns_dict0(): # step 2\n",
    "    #filling the json columons value with 0 and return dict\n",
    "    with open(\"..\\columns.json\", \"r\") as f:\n",
    "        data_columns = json.load(f)\n",
    "\n",
    "    data_column_dict_0 = {}\n",
    "    for column in data_columns[\"data_columns\"]:\n",
    "        data_column_dict_0[column] = 0 \n",
    "\n",
    "    return data_column_dict_0\n",
    "\n",
    "\n",
    "def update_dict_values(main_dict, sec_dict): # step 3\n",
    "  #Returns a dictionary with the keys in the main dictionary and with the values ​​of sec_dict\n",
    "  # input main_dict= {\"Avi\":0 ,\"Beth\":0 ,\"Gamil\":0}\n",
    "  # input sec_dict ={\"Noam\":12 ,\"Beth\":2,\"Avi\":1 }\n",
    "  # output {'Avi': 1, 'Beth': 2, 'Gamil': 0}\n",
    "  \n",
    "  updated_main_dict = {}\n",
    "  for key in main_dict:\n",
    "    if key in sec_dict:\n",
    "      updated_main_dict[key] = sec_dict[key]\n",
    "    else:\n",
    "      updated_main_dict[key] = main_dict[key]\n",
    "  return updated_main_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#input features\n",
    "def input_feature_values(zone_list,input_date,input_time,full_dt): #step 1\n",
    "# def input_feature_values(): #step 1\n",
    "\n",
    "    import pandas as pd\n",
    "        \n",
    "    # input_time = '15:12'\n",
    "    # input_date = '2022-12-30'\n",
    "    # full_dt = input_date + ' ' +input_time+':00' #'2022-12-31 22:00:00' \n",
    "    # zone_list= ['Tribeca']\n",
    "    zones_dict = getZones(zone_list)\n",
    "    weekday_dict = getWeekDay(input_date)\n",
    "    time_bin_dict =getTimeBinned(input_time)\n",
    "    weather_dict =getWeather(full_dt )\n",
    "\n",
    "    ## merge the all dicts\n",
    "    feature_input_dict = {**zones_dict, **weekday_dict , **time_bin_dict, **weather_dict}\n",
    "\n",
    "    #lower dict keys\n",
    "    feature_input_dict = lower_dict_keys(feature_input_dict)\n",
    "\n",
    "    #import the json columons and fill with values 0\n",
    "    json_columons =json_columns_dict0()\n",
    "\n",
    "    #create the dict with all sample of coulmons\n",
    "    model_sample_dict = update_dict_values(json_columons,feature_input_dict)\n",
    "\n",
    "    ## convert the dict to dataframe\n",
    "    model_sample_df = pd.DataFrame(model_sample_dict, index=[0])\n",
    "\n",
    "    \n",
    "    #import the xgboost model and predict\n",
    "    taxi_predict_model =get_model()\n",
    "    #predicted\n",
    "    resu_num_of_taxis=taxi_predict_model.predict(model_sample_df)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return resu_num_of_taxis\n",
    "\n",
    "\n",
    "def lower_dict_keys(dictionary): #lower dict keys\n",
    "    lower_dict = {}\n",
    "    for key in dictionary:\n",
    "        lower_key = key.lower()\n",
    "        lower_dict[lower_key] = dictionary[key]\n",
    "    return lower_dict\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################################### ETL\n",
    "def get_hours_label(min: int, max: int):\n",
    "    \"\"\" the function creates a list of labels in the format 00:00 - 00:59 for\n",
    "        example\n",
    "\n",
    "    Args:\n",
    "        min (int): min hour (0)\n",
    "        max (int): max hour (24)\n",
    "\n",
    "    Returns:\n",
    "        List: Returns a list of strings ( labels )\n",
    "    \"\"\"\n",
    "    return [f'{s:02d}:00 - {s:02d}:59' for s in range(min, max)]\n",
    "\n",
    "\n",
    "def getTimeBinned(input_date):\n",
    "    input_date = '17:40'\n",
    "    #create var of time_bin\n",
    "    date_dt = datetime.datetime.strptime(input_date,'%H:%M')\n",
    "    hours_input = str(date_dt.hour)\n",
    "\n",
    "    model_hour_input = f'{hours_input:02}:00 - {hours_input:02}:59'\n",
    "    label_hour_list = get_hours_label(0,24)\n",
    "\n",
    "    # #create dict hour_bin\n",
    "    Dict_hourBin ={}\n",
    "\n",
    "    for label in label_hour_list:\n",
    "        if label == model_hour_input:\n",
    "            Dict_hourBin[label] =1\n",
    "        else:\n",
    "            Dict_hourBin[label] = 0\n",
    "    return Dict_hourBin\n",
    "\n",
    "def getWeekDay(input_date):\n",
    "    input_date = '2022-12-30'\n",
    "\n",
    "    #convert data to dt type\n",
    "    date_time_obj = datetime.datetime.strptime(input_date, '%Y-%m-%d')\n",
    "\n",
    "    #create var of day of week for model\n",
    "    day_of_week  = date_time_obj.weekday()\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    model_weekDay_input = day_names[day_of_week]\n",
    "\n",
    "    #create dict\n",
    "    dict_weekday ={}\n",
    "\n",
    "    for every_day in day_names:\n",
    "        if every_day == model_weekDay_input:\n",
    "            dict_weekday[every_day] =1\n",
    "        else:\n",
    "            dict_weekday[every_day] = 0\n",
    "\n",
    "    return dict_weekday\n",
    "\n",
    "\n",
    "#קריאת נתוני מזג האוויר של התקופה הקרובה\n",
    "def getWeather_Format_unix():\n",
    "\n",
    "    # Manhattan coordinates\n",
    "    lat =  40.7834\n",
    "    lon = -73.9662\n",
    "\n",
    "    api_key = \"9bbe29045340e664d456449c4584d432\"\n",
    "\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&exclude=minutely&appid={api_key}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    Raw_Weather_Data = response.json()\n",
    "\n",
    "    return Raw_Weather_Data\n",
    "\n",
    "#ממיר מתאריך ושעה להצפנת מחשב\n",
    "def Convert_DT_To_unix_timestamp(date_request): #convert  '%Y-%m-%d %H:%M:%S to timestamp\n",
    "    \"\"\"Receiving the client's time and date data is in the form\n",
    "    '%Y-%m-%d %H:%M:%S\n",
    "     And this data is converted to the same type\n",
    "    as the ones in the API which are timestamped\n",
    "    \"\"\"\"\"\n",
    "    date_time_obj = datetime.datetime.strptime(date_request, '%Y-%m-%d %H:%M:%S')\n",
    "    unix_timestamp = date_time_obj.timestamp()\n",
    "    Customer_unix_timestamp = int(unix_timestamp)\n",
    "    return Customer_unix_timestamp \n",
    "\n",
    "def kelvin_to_fahrenheit(temp_kelvin):\n",
    "    #The API temperature data is in Kelvin \n",
    "    #and the temperature data in our model is in Fahrenheit\n",
    "  temp_fahrenheit = 9/5 * (temp_kelvin - 273) + 32\n",
    "  return temp_fahrenheit\n",
    "\n",
    "\n",
    "def getWeather(data_client):\n",
    "    \"\"\"\"Takes time and date data from the client like\n",
    "    '2022-12-30 21:00:00'   \n",
    "    and returns the weather data to the model\"\"\"\n",
    "\n",
    "    weather_data_API = getWeather_Format_unix()\n",
    "\n",
    "    # data_client = '2022-12-31 22:00:00' ########### for example\n",
    "    dt_API = Convert_DT_To_unix_timestamp(data_client) \n",
    "\n",
    "    global Tdep\n",
    "    global TempAvg_f\n",
    "    global cdd_total\n",
    "    global rain\n",
    "    global new_snow\n",
    "    global snow_dep\n",
    "\n",
    "    # Variables for CDD calculation\n",
    "    cdd_total = 0\n",
    "\n",
    "\n",
    "\n",
    "    data = weather_data_API['hourly']\n",
    "    result = [hourly_data for hourly_data in data if hourly_data['dt'] == dt_API]\n",
    "    if result:\n",
    "        # calculate Tavg\n",
    "        TempAvg_kelvin = ((result[0][\"temp\"] + result[0][\"feels_like\"]) / 2)\n",
    "        TempAvg_f = kelvin_to_fahrenheit(TempAvg_kelvin)\n",
    "\n",
    "        # Tdep\n",
    "        Tdep =0\n",
    "\n",
    "        # calculate CDD\n",
    "        temperature = result[0][\"temp\"]\n",
    "        temperature_fahrenheit = kelvin_to_fahrenheit(temperature)\n",
    "        threshold_temperature_f = 70 # threshold temperature in Fahrenheit\n",
    "        cdd = temperature_fahrenheit - threshold_temperature_f\n",
    "        if cdd > 0:\n",
    "            cdd_total += cdd\n",
    "        \n",
    "        # retrieve rain 1h\n",
    "        if 'rain' in result:\n",
    "          rain = result[0][\"rain\"][\"1h\"]\n",
    "        else:\n",
    "         rain =0\n",
    "\n",
    "        # retrieve snow 1h\n",
    "        if 'snow' in result:\n",
    "            new_snow = result[0][\"snow\"][\"1h\"] \n",
    "            snow_dep = result[0][\"snow\"][\"1h\"] \n",
    "        else:\n",
    "            new_snow , snow_dep = 0 , 0\n",
    "            \n",
    "    return {\n",
    "        'Tavg':TempAvg_f,\n",
    "        'Tdep':Tdep,\n",
    "        'CDD':cdd_total,\n",
    "        'Precipitation':rain,\n",
    "        'new_snow':new_snow,\n",
    "        'snow_depth':snow_dep}\n",
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 152],\n",
    "    \"Central Harlem\": [42, 41],\n",
    "    \"Morningside Heights\": [166],\n",
    "    \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "    \"Central Park\": [43],\n",
    "    \"Spanish Harlem\": [74, 75],\n",
    "    \"Randall's Island\": [194],\n",
    "    \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "    \"Roosevelt Island\": [202],\n",
    "    \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "    \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "    \"Kips Bay\": [137],\n",
    "    \"Stuyvesant Town\": [224],\n",
    "    \"Chelsea\": [246, 68, 90],\n",
    "    \"Flatiron District\": [186],\n",
    "    \"West Village\": [158, 249],\n",
    "    \"Greenwich Village\": [113, 114],\n",
    "    \"East Village\": [79, 4],\n",
    "    \"Soho\": [125, 221, 144],\n",
    "    \"Lower East Side\": [148, 232],\n",
    "    \"Tribeca\": [231],\n",
    "    \"Two Bridges\": [45],\n",
    "    \"Battery Park City\": [13, 12],\n",
    "    \"Financial District\": [209, 261, 87, 88, 12]\n",
    "}\n",
    "\n",
    "\n",
    "def getZones(list_zone_names): #input string on zone_names example zone_list[\"Inwood\"]\n",
    "    # zone_names = [\"Tribeca\",\"Two Bridges\"]\n",
    "    # print(create_dict(zone_names)) \n",
    "    new_dict_int = {}\n",
    "    new_dict_string ={}\n",
    "    \n",
    "    # fill with 1 the user zones\n",
    "    for name in list_zone_names:\n",
    "        if name in zones_to_name_dict:\n",
    "            for value in zones_to_name_dict[name]:\n",
    "                new_dict_int[value] = 1\n",
    "\n",
    "    \n",
    "    # #convert dtypes keys from int to string\n",
    "    for key, value in new_dict_int.items():\n",
    "        new_key = str(key)\n",
    "        new_dict_string[new_key] = value\n",
    "    \n",
    "\n",
    "    return new_dict_string  # {153: 1, 128: 1, 127: 1}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_features_input(time):\n",
    "    # zone = requests.json['zone'] #user give list of string\n",
    "    # date = request.json['date']\n",
    "    # time = requests.json['time']\n",
    "    # time = '2022-12-30 17:40'\n",
    "\n",
    "    # zone_id = getZones(zone)\n",
    "    time_binned = getTimeBinned(time)\n",
    "    return time_binned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# def load_saved_artifacts():\n",
    "    # return print(\"loading saved artifacts..start\")\n",
    "    # global __data_columns\n",
    "    \n",
    "    # with open(\"./artifacts/columns.json\",'r') as f:\n",
    "        # __data_columns =json.load(f)['data_columns']\n",
    "\n",
    "    \n",
    "    # return print(\"Loaded the features\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    # print(\"we started python Flask for my model\")\n",
    "    # server.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'XGBRegressor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22896/1123774089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0m__model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'XGBRegressor' object is not callable"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "__model(mor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create a map centered on New York City\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Display the map\n",
    "# nyc_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a marker at the Empire State Building\n",
    "folium.Marker(\n",
    "    location=[40.7484, -73.9857],\n",
    "    popup='Empire State Building',\n",
    "    icon=folium.Icon(icon='info-sign')\n",
    ").add_to(nyc_map)\n",
    "\n",
    "# Add a line connecting the Empire State Building and Central Park\n",
    "folium.PolyLine(\n",
    "    locations=[[40.7484, -73.9857], [40.7850, -73.9683]],\n",
    "    color='red',\n",
    "    weight=2.5,\n",
    "    opacity=1\n",
    ").add_to(nyc_map)\n",
    "\n",
    "# Add a polygon around Central Park\n",
    "folium.Polygon(\n",
    "    locations=[[40.7925, -73.9663], [40.7690, -73.9495], [40.7640, -73.9740]],\n",
    "    color='green',\n",
    "    fill=True,\n",
    "    fill_color='green'\n",
    ").add_to(nyc_map)\n",
    "\n",
    "# Display the updated map\n",
    "# nyc_map\n",
    "\n",
    "zones_to_name_dict={\n",
    "    \"Inwood\": [153, 128, 127],\n",
    "    \"Washington Heights\": [120, 244],\n",
    "    \"Hamilton Heights\": [116, 152],\n",
    "    \"Central Harlem\": [42, 41],\n",
    "    \"Morningside Heights\": [166],\n",
    "    \"Upper West Side\": [24, 151, 238, 239, 143, 142],\n",
    "    \"Central Park\": [43],\n",
    "    \"Spanish Harlem\": [74, 75],\n",
    "    \"Randall's Island\": [194],\n",
    "    \"Upper East Side\": [236, 263, 262, 237, 141, 140],\n",
    "    \"Roosevelt Island\": [202],\n",
    "    \"Midtown West\": [50, 48, 163, 230, 161, 100, 164],\n",
    "    \"Midtown East\": [170, 162, 229, 233, 170],\n",
    "    \"Kips Bay\": [137],\n",
    "    \"Stuyvesant Town\": [224],\n",
    "    \"Chelsea\": [246, 68, 90],\n",
    "    \"Flatiron District\": [186],\n",
    "    \"West Village\": [158, 249],\n",
    "    \"Greenwich Village\": [113, 114],\n",
    "    \"East Village\": [79, 4],\n",
    "    \"Soho\": [125, 221, 144],\n",
    "    \"Lower East Side\": [148, 232],\n",
    "    \"Tribeca\": [231],\n",
    "    \"Two Bridges\": [45],\n",
    "    \"Battery Park City\": [13, 12],\n",
    "    \"Financial District\": [209, 261, 87, 88, 12]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Map' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7512/2817208116.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m40.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m73.9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoom_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_map.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Map' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "# import folium\n",
    "\n",
    "# # Load the GeoJSON data of Manhattan's neighborhoods\n",
    "# manhattan_geo = r'manhattan_neighborhoods.geojson'\n",
    "\n",
    "# # Create the map\n",
    "# m = folium.Map(location=[40.7831, -73.9712], zoom_start=12)\n",
    "\n",
    "# # Add the GeoJSON data to the map\n",
    "# folium.GeoJson(manhattan_geo, name='geojson').add_to(m)\n",
    "\n",
    "# # Display the map\n",
    "# # m\n",
    "\n",
    "import folium\n",
    "\n",
    "manhattan_map = folium.Map(location=[40.7831, -73.9712], zoom_start=12)\n",
    "# manhattan_map\n",
    "folium.Marker(\n",
    "    location=[40.7831, -73.9712],\n",
    "    popup='Central Park',\n",
    "    icon=folium.Icon(icon='cloud')\n",
    ").add_to(manhattan_map)\n",
    "from IPython.display import display\n",
    "# display(m)\n",
    "\n",
    "m = folium.Map(location=[40.75, -73.9], zoom_start=12)\n",
    "m.show()\n",
    "\n",
    "m.save('my_map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'manhattan_zones.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7512/740857619.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"manhattan_zones.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Create a map centered on Manhattan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'manhattan_zones.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.taxi_zones.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7512/2698541207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmanhattan_zones_ID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanhattan_zones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LocationID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmanhattan_zones_ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mget_manhattan_zones_ID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7512/2698541207.py\u001b[0m in \u001b[0;36mget_manhattan_zones_ID\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# #Create List of the all ZoneID in Manhattan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_manhattan_zones_ID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mnyc_zones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.taxi_zones.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmanhattan_zones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnyc_zones\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnyc_zones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'borough'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;34m'Manhattan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmanhattan_zones_ID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanhattan_zones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LocationID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.taxi_zones.csv'"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"manhattan_zones.csv\")\n",
    "\n",
    "# #Create List of the all ZoneID in Manhattan\n",
    "def get_manhattan_zones_ID():\n",
    "    nyc_zones = pd.read_csv('.taxi_zones.csv')\n",
    "    manhattan_zones = nyc_zones.loc[nyc_zones['borough']== 'Manhattan']\n",
    "    manhattan_zones_ID = manhattan_zones['LocationID'].tolist()\n",
    "    return manhattan_zones_ID\n",
    "x =get_manhattan_zones_ID()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "path/to/manhattan_zones.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mfiona\\_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfiona\\_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: path/to/manhattan_zones.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7512/2687300415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mshapefile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"path/to/manhattan_zones.shp\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mgdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapefile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mgdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fiona\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         return _read_file_fiona(\n\u001b[0m\u001b[0;32m    260\u001b[0m             \u001b[0mpath_or_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36m_read_file_fiona\u001b[1;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m             \u001b[0mcrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrs_wkt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;31m# attempt to get EPSG code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fiona\\env.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fiona\\__init__.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0m\u001b[0;32m    279\u001b[0m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0;32m    280\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\omrid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fiona\\collection.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mfiona\\ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfiona\\_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: path/to/manhattan_zones.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# import folium\n",
    "\n",
    "# # Create a map object\n",
    "# m = folium.Map(location=[40.7831, -73.9712], zoom_start=12)\n",
    "\n",
    "# # Add a marker for each zone ID in the list\n",
    "# for zone_id in manhattan_zone_ids:\n",
    "#     folium.Marker(location=[zone_id.latitude, zone_id.longitude],\n",
    "#                   popup=zone_id.zone_name).add_to(m)\n",
    "\n",
    "# # Display the map\n",
    "# m\n",
    "import geopandas as gpd\n",
    "\n",
    "shapefile = \"path/to/manhattan_zones.shp\"\n",
    "gdf = gpd.read_file(shapefile)\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae7b14c5e53bbf41a97b172ade6093f5b3a59ea6c2c9455e8d94ad87db26471c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
